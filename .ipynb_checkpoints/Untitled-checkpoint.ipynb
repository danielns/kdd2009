{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_train_database():\n",
    "    train_dataset = pd.read_table('datasets/orange_small_train.data', sep='\\t', header=0)\n",
    "    variaveis_categoricas = list(train_dataset)[10:]\n",
    "    #train_dataset = pd.get_dummies(train_dataset, columns=variaveis_categoricas)\n",
    "    train_dataset = train_dataset.drop(variaveis_categoricas, axis=1)\n",
    "    train_dataset = train_dataset.fillna(0)\n",
    "    #train_dataset = train_dataset.as_matrix()\n",
    "    #train_labels_appetency = np.genfromtxt('datasets/orange_small_train_appetency.labels', dtype=None)\n",
    "    #train_labels_upselling = np.genfromtxt('datasets/orange_small_train_upselling.labels', dtype=None)\n",
    "    train_labels_appetency = pd.read_table('datasets/orange_small_train_appetency.labels', sep='\\t', header=-1)\n",
    "    train_labels_upselling = pd.read_table('datasets/orange_small_train_upselling.labels', sep='\\t', header=0)\n",
    "    return train_dataset, train_labels_appetency , train_labels_upselling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dataset, train_labels_appetency, train_labels_upselling = load_train_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False], dtype=bool)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(np.isnan(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_labels_appetency[train_labels_appetency==-1] = 0\n",
    "#test_dataset = np.genfromtxt('datasets/orange_small_test.data', delimiter='\\t', dtype=None,names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dataset =(train_dataset-train_dataset.mean())/train_dataset.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_labels_appetency = train_labels_appetency.as_matrix()\n",
    "train_dataset = train_dataset.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_placeholders(n_x, n_y):\n",
    "    \"\"\"\n",
    "    Creates the placeholders for the tensorflow session.\n",
    "    \n",
    "    Arguments:\n",
    "    n_H0 -- scalar, height of an input image\n",
    "    n_W0 -- scalar, width of an input image\n",
    "    n_C0 -- scalar, number of channels of the input\n",
    "    n_y -- scalar, number of classes\n",
    "        \n",
    "    Returns:\n",
    "    X -- placeholder for the data input, of shape [None, n_H0, n_W0, n_C0] and dtype \"float\"\n",
    "    Y -- placeholder for the input labels, of shape [None, n_y] and dtype \"float\"\n",
    "    \"\"\"\n",
    "\n",
    "    ### START CODE HERE ### (â‰ˆ2 lines)\n",
    "    X = tf.placeholder(shape=(None, n_x), dtype=tf.float32)\n",
    "    Y = tf.placeholder(shape=(None, n_y), dtype=tf.float32)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.01\n",
    "num_steps = 1000\n",
    "batch_size = 128\n",
    "display_step = 100\n",
    "\n",
    "# Network Parameters\n",
    "n_hidden_1 = 40 # 1st layer number of neurons\n",
    "n_hidden_2 = 20 # 2nd layer number of neurons\n",
    "num_input = 190 # MNIST data input (img shape: 28*28)\n",
    "num_classes = 1 # MNIST total classes (0-9 digits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={'train_dataset': train_dataset}, y=train_labels_appetency,\n",
    "    batch_size=batch_size, num_epochs=None, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the neural network\n",
    "def forward_propagation1(x):\n",
    "    \n",
    "    # Hidden fully connected layer with 256 neurons\n",
    "    layer_1 = tf.layers.dense(x, n_hidden_1)\n",
    "    # Hidden fully connected layer with 256 neurons\n",
    "    layer_2 = tf.layers.dense(layer_1, n_hidden_2)\n",
    "    # Output fully connected layer with a neuron for each class\n",
    "    out_layer = tf.layers.dense(layer_2, num_classes, activation=tf.nn.sigmoid)\n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels_appetency.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z3 = [[ 0.4976145 ]\n",
      " [ 0.58165652]\n",
      " [ 0.50505   ]\n",
      " ..., \n",
      " [ 0.50018185]\n",
      " [ 0.58063203]\n",
      " [ 0.49795118]]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    np.random.seed(1)\n",
    "    X, Y = create_placeholders(train_dataset.shape[1], train_labels_appetency.shape[1])\n",
    "    \n",
    "    Z3 = forward_propagation(X)\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    a = sess.run(Z3, {X: train_dataset})\n",
    "    \n",
    "    print(\"Z3 = \" + str(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: compute_cost \n",
    "\n",
    "def compute_cost(Z3, Y):\n",
    "    \"\"\"\n",
    "    Computes the cost\n",
    "    \n",
    "    Arguments:\n",
    "    Z3 -- output of forward propagation (output of the last LINEAR unit), of shape (6, number of examples)\n",
    "    Y -- \"true\" labels vector placeholder, same shape as Z3\n",
    "    \n",
    "    Returns:\n",
    "    cost - Tensor of the cost function\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ### (1 line of code)\n",
    "    cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = Z3, labels = Y))\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost = 0.9765955\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    np.random.seed(1)\n",
    "    X, Y = create_placeholders(train_dataset.shape[1], train_labels_appetency.shape[1])\n",
    "    \n",
    "    Z3 = forward_propagation(X)\n",
    "    cost = compute_cost(Z3, Y)\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    a = sess.run(cost, {X: train_dataset, Y: train_labels_appetency})\n",
    "    print(\"cost = \" + str(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_mini_batches(X, Y, mini_batch_size = 3000, seed = 0):\n",
    "    \"\"\"\n",
    "    Creates a list of random minibatches from (X, Y)\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input data, of shape (input size, number of examples) (m, Hi, Wi, Ci)\n",
    "    Y -- true \"label\" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples) (m, n_y)\n",
    "    mini_batch_size - size of the mini-batches, integer\n",
    "    seed -- this is only for the purpose of grading, so that you're \"random minibatches are the same as ours.\n",
    "    \n",
    "    Returns:\n",
    "    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)\n",
    "    \"\"\"\n",
    "    \n",
    "    m = X.shape[0]                  # number of training examples\n",
    "    mini_batches = []\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Step 1: Shuffle (X, Y)\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_X = X[permutation,:]\n",
    "    shuffled_Y = Y[permutation,:]\n",
    "\n",
    "    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n",
    "    num_complete_minibatches = m//mini_batch_size # number of mini batches of size mini_batch_size in your partitionning\n",
    "    for k in range(0, num_complete_minibatches):\n",
    "        mini_batch_X = shuffled_X[k * mini_batch_size : k * mini_batch_size + mini_batch_size,:]\n",
    "        mini_batch_Y = shuffled_Y[k * mini_batch_size : k * mini_batch_size + mini_batch_size,:]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    # Handling the end case (last mini-batch < mini_batch_size)\n",
    "    if m % mini_batch_size != 0:\n",
    "        mini_batch_X = shuffled_X[num_complete_minibatches * mini_batch_size : m,:]\n",
    "        mini_batch_Y = shuffled_Y[num_complete_minibatches * mini_batch_size : m,:]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    return mini_batches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = random_mini_batches(train_dataset, train_labels_appetency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x[16][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48000"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "16*3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, X_test=None, Y_test=None, learning_rate = 0.009,\n",
    "          num_epochs = 100, minibatch_size = 64, print_cost = True):\n",
    "    \"\"\"\n",
    "    Implements a three-layer ConvNet in Tensorflow:\n",
    "    CONV2D -> RELU -> MAXPOOL -> CONV2D -> RELU -> MAXPOOL -> FLATTEN -> FULLYCONNECTED\n",
    "    \n",
    "    Arguments:\n",
    "    X_train -- training set, of shape (None, 64, 64, 3)\n",
    "    Y_train -- test set, of shape (None, n_y = 6)\n",
    "    X_test -- training set, of shape (None, 64, 64, 3)\n",
    "    Y_test -- test set, of shape (None, n_y = 6)\n",
    "    learning_rate -- learning rate of the optimization\n",
    "    num_epochs -- number of epochs of the optimization loop\n",
    "    minibatch_size -- size of a minibatch\n",
    "    print_cost -- True to print the cost every 100 epochs\n",
    "    \n",
    "    Returns:\n",
    "    train_accuracy -- real number, accuracy on the train set (X_train)\n",
    "    test_accuracy -- real number, testing accuracy on the test set (X_test)\n",
    "    parameters -- parameters learnt by the model. They can then be used to predict.\n",
    "    \"\"\"\n",
    "    \n",
    "    ops.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n",
    "    tf.set_random_seed(1)                             # to keep results consistent (tensorflow seed)\n",
    "    seed = 3                                          # to keep results consistent (numpy seed)\n",
    "    (m, n_x) = X_train.shape             \n",
    "    n_y = Y_train.shape[1]                            \n",
    "    costs = []                                        # To keep track of the cost\n",
    "    \n",
    "    # Create Placeholders of the correct shape\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    X, Y = create_placeholders(n_x, n_y)\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    \n",
    "    # Forward propagation: Build the forward propagation in the tensorflow graph\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    Z3 = forward_propagation(X)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Cost function: Add cost function to tensorflow graph\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    cost = compute_cost(Z3, Y)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer that minimizes the cost.\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Initialize all the variables globally\n",
    "    init = tf.global_variables_initializer()\n",
    "     \n",
    "    # Start the session to compute the tensorflow graph\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        # Run the initialization\n",
    "        sess.run(init)\n",
    "        sess.run(tf.initialize_local_variables())\n",
    "        \n",
    "        # Do the training loop\n",
    "        for epoch in range(num_epochs):\n",
    "\n",
    "            minibatch_cost = 0.\n",
    "            num_minibatches = int(m / minibatch_size) # number of minibatches of size minibatch_size in the train set\n",
    "            seed = seed + 1\n",
    "            minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)\n",
    "\n",
    "            for minibatch in minibatches:\n",
    "\n",
    "                # Select a minibatch\n",
    "                (minibatch_X, minibatch_Y) = minibatch\n",
    "                # IMPORTANT: The line that runs the graph on a minibatch.\n",
    "                # Run the session to execute the optimizer and the cost, the feedict should contain a minibatch for (X,Y).\n",
    "                ### START CODE HERE ### (1 line)\n",
    "                _ , temp_cost = sess.run([optimizer, cost], feed_dict={X: minibatch_X, Y: minibatch_Y})\n",
    "                ### END CODE HERE ###\n",
    "                \n",
    "                minibatch_cost += temp_cost / num_minibatches\n",
    "                \n",
    "\n",
    "            # Print the cost every epoch\n",
    "            if print_cost == True and epoch % 5 == 0:\n",
    "                print (\"Cost after epoch %i: %f\" % (epoch, minibatch_cost))\n",
    "            if print_cost == True and epoch % 1 == 0:\n",
    "                costs.append(minibatch_cost)\n",
    "        \n",
    "        \n",
    "        # plot the cost\n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per tens)')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()\n",
    "\n",
    "        # Calculate the correct predictions\n",
    "        predict_op = tf.round(Z3)\n",
    "        correct_prediction = tf.equal(predict_op, Y)\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "        auc = tf.contrib.metrics.streaming_auc(predict_op, Y)\n",
    "        train_auc = sess.run(auc)\n",
    "        #print(train_accuracy)\n",
    "        # Calculate accuracy on the test set\n",
    "        #\n",
    "        #tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "        #print(accuracy)\n",
    "        train_accuracy = accuracy.eval({X: X_train, Y: Y_train})\n",
    "        #test_accuracy = accuracy.eval({X: X_test, Y: Y_test})\n",
    "        print(\"Train Accuracy:\", train_accuracy)\n",
    "        print(\"Train Accuracy:\", train_auc)\n",
    "        #print(\"Test Accuracy:\", test_accuracy)\n",
    "        #print(sess.run(tf.reduce_sum(Z3, axis=1)))\n",
    "        return Z3 #train_accuracy #, test_accuracy, parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\danie\\Anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\util\\tf_should_use.py:170: initialize_local_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.local_variables_initializer` instead.\n",
      "Cost after epoch 0: 0.723877\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x168364151d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (50000, 190) for Tensor 'Round:0', which has shape '(?, 1)'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-3f7c736c7fa4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels_appetency\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-60-3532e0b2c934>\u001b[0m in \u001b[0;36mmodel\u001b[1;34m(X_train, Y_train, X_test, Y_test, learning_rate, num_epochs, minibatch_size, print_cost)\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorrect_prediction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"float\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m         \u001b[0mauc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstreaming_auc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredict_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 101\u001b[1;33m         \u001b[0mtrain_auc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mauc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mpredict_op\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    102\u001b[0m         \u001b[1;31m#print(train_accuracy)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m         \u001b[1;31m# Calculate accuracy on the test set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    787\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 789\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    790\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\dl\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    973\u001b[0m                 \u001b[1;34m'Cannot feed value of shape %r for Tensor %r, '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    974\u001b[0m                 \u001b[1;34m'which has shape %r'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 975\u001b[1;33m                 % (np_val.shape, subfeed_t.name, str(subfeed_t.get_shape())))\n\u001b[0m\u001b[0;32m    976\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    977\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Tensor %s may not be fed.'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot feed value of shape (50000, 190) for Tensor 'Round:0', which has shape '(?, 1)'"
     ]
    }
   ],
   "source": [
    "train_accuracy = model(train_dataset, train_labels_appetency, num_epochs = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Sum:0' shape=() dtype=float32>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the model function (following TF Estimator Template)\n",
    "def model_fn(features, labels, mode):\n",
    "    \n",
    "        \n",
    "    # Build the neural network\n",
    "    logits = neural_net(features)\n",
    "    \n",
    "    # Predictions\n",
    "    pred_classes = tf.round(logits)\n",
    "    #tf.Print(pred_classes, [pred_classes])\n",
    "    #print(pred_classes.eval())\n",
    "    a = tf.Print(pred_classes, [pred_classes], message=\"This is a: \")\n",
    "    pred_probas = tf.nn.sigmoid(logits)\n",
    "    \n",
    "    # If prediction mode, early return\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode, predictions=pred_probas) \n",
    "        \n",
    "    # Define loss and optimizer\n",
    "    loss_op = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "        logits=logits,  labels=tf.cast(labels, dtype=tf.float64)))\n",
    "    \n",
    "       \n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "    train_op = optimizer.minimize(loss_op, global_step=tf.train.get_global_step())\n",
    "    \n",
    "    # Evaluate the accuracy of the model\n",
    "    acc_op = tf.metrics.accuracy(labels=labels, predictions=pred_classes)\n",
    "    #acc_op = tf.metrics.auc(labels=labels, predictions=pred_classes)\n",
    "    \n",
    "\n",
    "    \n",
    "    # TF Estimators requires to return a EstimatorSpec, that specify\n",
    "    # the different ops for training, evaluating, ...\n",
    "    estim_specs = tf.estimator.EstimatorSpec(\n",
    "      mode=mode,\n",
    "      predictions=pred_classes,\n",
    "      loss=loss_op,\n",
    "      train_op=train_op,\n",
    "      eval_metric_ops={'accuracy': acc_op}\n",
    "    )\n",
    "\n",
    "    return estim_specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\danie\\AppData\\Local\\Temp\\tmputo5toym\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\danie\\\\AppData\\\\Local\\\\Temp\\\\tmputo5toym', '_tf_random_seed': 1, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_save_checkpoints_steps': None, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000}\n"
     ]
    }
   ],
   "source": [
    "model = tf.estimator.Estimator(model_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\danie\\AppData\\Local\\Temp\\tmputo5toym\\model.ckpt.\n",
      "INFO:tensorflow:loss = 83894.59865183625, step = 1\n",
      "INFO:tensorflow:Loss for final step: 83894.59865183625.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x1d0ddc1f1d0>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(input_fn, steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2018-02-28-20:25:10\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\m1312932\\AppData\\Local\\Temp\\tmpbb6d5zr_\\model.ckpt-1\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-28-20:25:12\n",
      "INFO:tensorflow:Saving dict for global step 1: accuracy = 0.5, global_step = 1, loss = 9.14945e+18\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.5, 'global_step': 1, 'loss': 9.149448e+18}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the Model\n",
    "# Define the input function for evaluating\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={'train_dataset': train_dataset.as_matrix()}, y=train_labels_appetency.as_matrix(),\n",
    "    batch_size=batch_size, shuffle=False)\n",
    "# Use the Estimator 'evaluate' method\n",
    "model.evaluate(input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
